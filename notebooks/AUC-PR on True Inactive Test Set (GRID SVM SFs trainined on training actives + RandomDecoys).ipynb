{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile, pickle\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from convert_pIC50_to_activity import bin_predicted_pIC50, bin_observed_pIC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "def enrichment_factor(y_true, y_score, percentage=1, pos_label=None, kind='fold'):\n",
    "    \"\"\"Computes enrichment factor for given percentage, i.e. EF_1% is\n",
    "    enrichment factor for first percent of given samples. This function assumes\n",
    "    that results are already sorted and samples with best predictions are first.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape=[n_samples]\n",
    "        True binary labels, in range {0,1} or {-1,1}. If positive label is\n",
    "        different than 1, it must be explicitly defined.\n",
    "\n",
    "    y_score : array, shape=[n_samples]\n",
    "        Scores for tested series of samples\n",
    "\n",
    "    percentage : int or float\n",
    "        The percentage for which EF is being calculated\n",
    "\n",
    "    pos_label: int\n",
    "        Positive label of samples (if other than 1)\n",
    "\n",
    "    kind: 'fold' or 'percentage' (default='fold')\n",
    "        Two kinds of enrichment factor: fold and percentage.\n",
    "        Fold shows the increase over random distribution (1 is random, the\n",
    "        higher EF the better enrichment). Percentage returns the fraction of\n",
    "        positive labels within the top x% of dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ef : float\n",
    "        Enrichment Factor for given percenage in range 0:1\n",
    "    \"\"\"\n",
    "    if pos_label is None:\n",
    "        pos_label = 1\n",
    "    labels = y_true == pos_label\n",
    "    assert labels.sum() > 0, \"There are no correct predicions. Double-check the pos_label\"\n",
    "    assert len(labels) > 0, \"Sample size must be greater than 0\"\n",
    "    # calculate fraction of positve labels\n",
    "    n_perc = int(ceil(percentage / 100. * len(labels)))\n",
    "    out = labels[:n_perc].sum() / n_perc\n",
    "    if kind == 'fold':\n",
    "        out /= (labels.sum() / len(labels))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_predicted_pIC50(row):\n",
    "    if row['Predicted_pIC50'] >= 5:\n",
    "        val = 'Active'\n",
    "    else:\n",
    "        val = \"Inactive\"\n",
    "    return val\n",
    "\n",
    "def bin_observed_pIC50(row):\n",
    "    if row['Observed_pIC50'] >= 5:\n",
    "        val = 'Active'\n",
    "    else:\n",
    "        val = 'Inactive'\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM GRID SF Model (Training actives + RandomDecoys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junaid/miniconda3/envs/Jupyter_Dock/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SVR from version 0.24.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "filename = \"../models/GRID_SVM_SFs_training_actives_and_RandomDecoys.sav\"\n",
    "GRID_SVM_SF = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GRID Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rdkit_grid_features_pubchems = np.load(\"../data/test_set/RDKit_Grid_Feature_Test_PubChem.zip\")\n",
    "test_rdkit_grid_features_pubchems = pd.DataFrame(test_rdkit_grid_features_pubchems['RDKit_Grid_Feature_Test_PubChem'])\n",
    "\n",
    "PubChems_Labels = pd.read_csv(\"../data/test_set/PubChem_IDs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_rdkit_grid_svm = GRID_SVM_SF.predict(test_rdkit_grid_features_pubchems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get AUC-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9419846969849105\n"
     ]
    }
   ],
   "source": [
    "svm_rdkit_grid_result = pd.DataFrame({\"Predicted_pIC50\": prediction_test_rdkit_grid_svm,\n",
    "                                     \"Observed_pIC50\": list(PubChems_Labels['pIC50'])})\n",
    "svm_rdkit_grid_result['Predicted_Activity'] = svm_rdkit_grid_result.apply(bin_predicted_pIC50, axis = 1)\n",
    "svm_rdkit_grid_result['Observed_Activity'] = svm_rdkit_grid_result.apply(bin_observed_pIC50,axis = 1)\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "svm_rdkit_grid_result['normalized_scores'] = (svm_rdkit_grid_result['Predicted_pIC50'] - svm_rdkit_grid_result['Predicted_pIC50'].min()) / (svm_rdkit_grid_result['Predicted_pIC50'].max() - svm_rdkit_grid_result['Predicted_pIC50'].min())\n",
    "precision_rdkit_grid_svm, recall_rdkit_grid_svm, threshold_rdkit_grid_svm = precision_recall_curve(svm_rdkit_grid_result['Observed_Activity'], svm_rdkit_grid_result['normalized_scores'], pos_label = 'Active')\n",
    "svm_rdkit_grid_precision_recall = pd.DataFrame({\"Precision\": precision_rdkit_grid_svm,\n",
    "                                               \"Recall\": recall_rdkit_grid_svm})\n",
    "print(auc(recall_rdkit_grid_svm, precision_rdkit_grid_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get EF1% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_active_score = pd.DataFrame(svm_rdkit_grid_result['Predicted_pIC50'])\n",
    "data_active_score['activity'] = svm_rdkit_grid_result['Observed_Activity']\n",
    "data_active_score.sort_values('Predicted_pIC50', inplace=True, ascending=False)\n",
    "enrichment_value= round(enrichment_factor(data_active_score['activity'], data_active_score['Predicted_pIC50'], percentage=1, pos_label='Active'))\n",
    "enrichment_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
